{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SkaiLord/ML-Lab/blob/main/ML_Assignment_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LAB 9 - KNN Classifier"
      ],
      "metadata": {
        "id": "rrBUood6mIjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN classifier from scratch without prebuild functions\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from collections import Counter\n",
        "\n",
        "# Loading & normalising features\n",
        "data = sb.load_dataset(\"iris\")\n",
        "X = data[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
        "y = data['species']\n",
        "scaler = MinMaxScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "normalized_df = pd.DataFrame(X_normalized, columns=X.columns)\n",
        "# print(normalized_df)\n",
        "\n",
        "def euclidean_distance(x1, x2):\n",
        "  return sum([(a - b) ** 2 for a, b in zip(x1, x2)]) ** 0.5\n",
        "\n",
        "def knn_classifier(X_train, y_train, x_test, k):\n",
        "  distances = [euclidean_distance(x_test, x_train) for x_train in X_train]\n",
        "  k_nearest_indices = sorted(range(len(distances)), key=lambda i: distances[i])[:k]\n",
        "  k_nearest_labels = [y_train[i] for i in k_nearest_indices]\n",
        "  most_common = Counter(k_nearest_labels).most_common(1)\n",
        "  return most_common[0][0]\n",
        "\n",
        "X_train = normalized_df.values.tolist()\n",
        "y_train = y.values.tolist()\n",
        "\n",
        "x_test = X_train[0]  # Example test data\n",
        "k = 5  # Number of neighbors\n",
        "\n",
        "predicted_label = knn_classifier(X_train, y_train, x_test, k)\n",
        "print(f\"Predicted label for x_test: {predicted_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ap8fDqzpTyH",
        "outputId": "c26ef1dc-842e-46e8-8b80-3096009f1f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label for x_test: setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "# Using the Iris dataset\n",
        "def load_iris():\n",
        "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "    df = pd.read_csv(url, header=None)\n",
        "    df.columns = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
        "    return df\n",
        "\n",
        "# Step 2: Min-Max Normalization\n",
        "def min_max_normalization(data):\n",
        "    data_min = data.min()\n",
        "    data_max = data.max()\n",
        "    return (data - data_min) / (data_max - data_min)\n",
        "\n",
        "# Step 3: KNN Classifier\n",
        "class KNN:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = [self._predict(x) for x in X]\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def _predict(self, x):\n",
        "        # Compute distances\n",
        "        distances = np.linalg.norm(self.X_train - x, axis=1)\n",
        "        # Get the indices of the k nearest neighbors\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        # Extract the labels of the k nearest neighbors\n",
        "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
        "        # Return the most common class label\n",
        "        most_common = Counter(k_nearest_labels).most_common(1)\n",
        "        return most_common[0][0]\n",
        "\n",
        "\n",
        "df = load_iris()\n",
        "\n",
        "# Preprocess the data\n",
        "features = df[['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']]\n",
        "labels = df['Species']\n",
        "\n",
        "# Normalize features\n",
        "normalized_features = min_max_normalization(features)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_size = int(0.8 * len(normalized_features))\n",
        "X_train = normalized_features[:train_size].values\n",
        "y_train = labels[:train_size].values\n",
        "X_test = normalized_features[train_size:].values\n",
        "y_test = labels[train_size:].values\n",
        "\n",
        "# Create KNN classifier and fit the model\n",
        "knn = KNN(k=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.sum(predictions == y_test) / len(y_test)\n",
        "print(f'Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbOcKTDarvAj",
        "outputId": "2376c67b-096d-4919-b17a-d4c3380c76a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.87\n"
          ]
        }
      ]
    }
  ]
}